---
title: "Multimodal Live API で、AIネイティブ次世代のリアルタイム会話型の学習サービスをつくってみた！"
emoji: "📘"
type: "tech"
topics: ["cloudrun", "firebase","ai","gemini","multimodal-live-api"]
published: true
---
### はじめに

こんにちは！宮本です！[Google Cloud AI Agent Hackathon 2025](https://zenn.dev/hackathons/2024-google-cloud-japan-ai-hackathon)のコンテストに応募します！
**内容おもしろそう！と思った方は、ぜひ応援のいいね！を押して、読み進めてください！**

突然ですが私には5歳と3歳の子どもがいます。彼らが成長していく過程でAIがもっと身近に活躍してくれたら、学びの可能性は一気に広がるのでは？ という期待をずっと抱いてきました。

今の若い世代は生まれたときからネット環境に慣れ親しんでおり、“デジタルネイティブ”世代だと言われていますが、その次の時代にあたる **“AIネイティブ世代”** という言葉も最近耳にしはじめました。
私の子供たちは、物心ついた頃からAIがあたりまえに存在する激動の時代を生きていく。そして、どんな学習体験をしながら成長していくのだろう……？
そんな思いを抱いた私が、ジャンジャン問題を出してくれるAI学習サービス「janjan-for-kids」というPoC（概念実証）という形で作ってみました。

:::message
現在 Gemini API は利用できるのは 18 歳以上の方のみです。
子供が利用できるAPIがないので公開サービスにできないアイデアでしたが、ハッカソンという形でならアイデアお披露目ができそうと思い概念実証の形で実装し、私が試しています。
:::
詳しくは[規約](https://ai.google.dev/gemini-api/terms?hl=ja)をご確認ください。


本記事では、「janjan-for-kids」で目指している世界観や開発の背景、具体的な特徴やシステムアーキテクチャ、さらに試作のなかで感じた課題点などを詳しくご紹介します。
AIネイティブ世代が、“自分のタイミング”で“自分のレベル”に合った学習を、まるで友達のようなAIと一緒に楽しめる――そんな未来をイメージしながら読んでいただけたら嬉しいです！

### サービスを作った背景と目的

私の息子（5歳）がちょうど足し算に目覚めて、毎日のように「5+7はいくつ？」「13+4はいくつ？」と問題をやっています。
ただ親である私や妻が忙しくて手が回らなかったり、同じような問題しか出せなくて飽きてしまったりすることがあります。

**「子どもの貴重な学習意欲を、私がサポートできずに逃してしまうのは本当にもったいない！」**

そう感じていた私が思いついたのが、「AIが学習パートナーになってくれればいいんじゃないか？」というアイデアでした。
どんなに忙しくても、AIが自動で問題を出し、答えを評価し、さらには学習履歴を蓄積してくれるなら、子どもの貴重なやる気を最大化できるはずです。こうして作ったのが「janjan-for-kids」です。

### 解決したい課題

本プロジェクトでは、とくに以下の3つの課題を意識して取り組みました。

1. **問題作りの負荷**
   毎日新しい問題を考えてあげるのは簡単ではありませんし、親がその都度作ると、問題が単調になってしまいがちです。
   さらに学習記録を蓄積しないと、子どもがどこでつまずいているのか把握しづらい…。

2. **音声モードの興味を持ってもらいづらさ**
   既存の音声AIサービス（たとえばChatGPTの高度な音声モードなど）をそのまま使ってみても、子どもが「なんだか怖い」と感じたり、興味を持たない。

3. **会話の起点が常に人間**
   子どもが「やりたい！」と思ったときに、いちいち親がAIと会話を始めるセッティングをするのは手間でした。子どもの自発性を大事にしたいのに、親の都合でブレーキがかかってしまうのはもったいない。

### 「janjan-for-kids」のサービス・機能について
まずはデモ動画をご覧ください。
https://www.youtube.com/watch?v=Te8r2B_DVJg

「janjan-for-kids」は先ほどの３つの課題を解決する機能を作成しました。


#### 1. リアルタイム音声の会話形式で勉強ができる！
リアルタイムでの音声会話をしながら、レベルに合った問題データをAIエージェントが自動で作成してくれます。レベルと問題難易度は、相対的に子どもの学習履歴をもとに自動で調整されます。

これにより問題を人力で用意する必要がなく、AIが学習の進捗を見ながら柔軟に子ども一人ひとりに合わせた問題を選び続けてくれます。次世代のAI家庭教師のような形に近づけました。

#### 2. 3Dキャラクターで親近感をアップ！
文字や音声だけよりも、画面に楽しげなキャラクターがいるだけで子どもは自然と興味を持ちました。そこでThree.jsを使った3Dキャラクターを導入し、音声に合わせて3Dモデルを動かすようにしています。
今回は単に音声だけに合わせて動かすだけですが、3Dモデル+AIエージェントが子供のパートナーとして活躍する未来がより可能性が見えてたように思います。

#### 3. 常駐型AIエージェントで子どもの学習タイミングを尊重！
カメラをオンにしてシステムが顔を認識し、「こんにちは、〇〇ちゃん！」という具合に自動的に学習をスタートする仕様にしました。
親がわざわざ「はい、今からAIと話すよ」とセットアップしなくても、子どもがやりたいと思ったタイミングで学習がはじまるのです。
今のAIエージェントは基本人間から話しかけないといけないものが多いですが、学習の起点を“子ども”に委ねるという大きなポイントになっています。


### システムアーキテクチャと工夫ポイント
こちらが主なシステムアーキテクチャで、Firebase、Cloud Run、Vertex AI の Multimodal Live APIを使って作成しました。

![システムアーキテクチャ](/images/71e5ff935108e2/system-architecture.jpg)

#### 1. Vertex AI の Multimodal Live API

会話をリアルタイム処理し、音声や映像をAIが素早く分析するためには、Vertex AI の Multimodal Live APIを利用しました。Google公式のサンプルが充実しているのでPoCとして取り組みやすく、開発スピードも大幅に上がりました。

以下２つの参考レポジトリが特に参考になりました。
- [Multimodal Live API Documentation](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/multimodal-live-api/README.md)
- [Multimodal Live API - Web console](https://github.com/google-gemini/multimodal-live-api-web-console)

#### 2. Cloud Run

ブラウザとVertex AIの間でWebSocket通信を中継するサーバーとして利用しています。
- **トークン検証によるユーザー管理**
  Firebase Authでログインしてフロントで得られる id_token 情報をCloud Runで検証し、正しいユーザーかどうかをチェック。
  これにより、子どもの学習データをきちんと区別できます。

- **システムプロントの分岐**
   Multimodal Live API は、ユーザー情報によってシステムプロントを分岐させています。
   最初は１つのシステムプロンプトにして、プロンプト内に条件を書いていましたが、ユーザーログインの有無でユーザーの情報もシステムプロンプトに入れることで精度が高まりました。

- **Tool Calling で出題した問題を登録**
   Cloud Run側で`add_math_question`のようなツールを呼び出し、Firestoreへ問題を追加・更新する流れを実装しています。

- **メインの学習プロンプト**
   問題の難易度を設定する際に、相対的な[問題難易度の基準]を把握させることで問題難易度を安定させました。
   ```
   【前回の問題の確認】
   - [現在のレベル]を確認と[今のレベルの問題]と[１つ前のレベルの問題]を把握し、[問題難易度の基準]とする。
   ```

#### 3. Firestore

学習問題や回答結果を記録するため、Firestoreを採用しました。

- **リアルタイム同期**
  Tool Calling で 出題時に追加された問題は、onSnapshotを使ってドキュメント更新を即時にブラウザへ反映されます。これによって出題された問題をスピーディに確認できます。


#### 4. Firebase Hosting
- **ホスティング**
   HTML/CSS/JS のWebコンテンツをホスティングしています。
   3Dモデルファイル（.obj）もホスティングしており、Three.jsで読み込むことで3Dキャラクターを表示しています。
- **顔認識**
   face-api.jsのモデルデータもホスティングしています。ブラウザだけで顔認識できる環境を用意するために利用しています。

#### 5. Firebase Auth

- 匿名認証を採用してユーザーごとの学習履歴を区別。
- 将来はGoogleアカウントやメール認証への移行も視野に入れつつ、PoC段階では最小限の設定で素早く実装できました。

### 作ってみてわかった「これからのAI×学習の未来」

PoCとはいえ、「janjan-for-kids」を実際に組み上げて動かしてみたところ、AIネイティブ世代がAIを活用して学習を深める未来が、想像以上にリアルに感じられました。
ほんの少し顔をみせるだけでAIが「今日も一緒に足し算しようか！」と声をかけてくれて、答えを言えばすぐに結果が返ってくる。
回答履歴は全部自動で蓄積され、子どもの苦手分野をAIがサポートしてくれる――このような形の学習スタイルが近い未来にやってくる気がします。

また、プロンプトを改善することで教育に対するスタンスもカスタマイズできるのでここはもっとチューニングのしがいがありそうです。

### 開発で苦労したポイント

1. **gemini-2.0-flash-exp は experimental モデル**
   - 英語のみが正式にサポートされており、日本語はカタコト混じりになってしまいます。
   - 特に数を数えるときに「ワンつ、ツゥーつ」と発話してしまうなど、が算数の問題をやる上で致命的でした。
   - 対策としてプロンプトに「必ず日本語のみを使用（英語や他言語を混ぜない）、数字は必ず漢数字（）を使用」と書き込むなど、細かいチューニングを実施しました。

2. **同時接続数が3で限界**
   - gemini-2.0-flash-expは実験的モデルのため、同時利用の枠が小さく、すぐにリソース上限に達してしまいます。。
   - PoCレベルでは問題ありませんが、一般公開や複数ユーザー同時利用を想定すると厳しく、今後のアップデートや他モデルの利用検討が必要だと痛感しました。


### 今後の展望とまとめ

今回は主に算数（足し算）を題材に機能を実装しましたが、「janjan-for-kids」には大きな拡張可能性があります。

- **国語・英語など他教科への展開**
  単語や文法の習得、発音チェックなど、音声×テキストの組み合わせでレベルに応じた問題を出題できるかもしれません。

- **理科や社会の実験サポート**
  子どもがやっている実験をカメラで捉えてAIがアドバイスを出すような、より高度なインタラクションも考えれそうだと思いました。

- **3Dモデルの作り込み・ゲーミフィケーション**
  学習を続けることでキャラクターが進化する、3Dアバターをカスタマイズできる、ポイントやバッジを集める――といった仕掛けを取り入れれば、もっと子どもが夢中になれる気がします。

もちろん、実際に広くサービス提供するには、日本語対応モデルの対応や子供が使える安全なAPIと、正式版ではリアルタイムAPIはコスト面でも費用が大きくかかりそうなどの課題があります。
しかしサービスを作ってみて、**「AIネイティブ世代がAIと一緒に学ぶ未来は割と近いな！」** と思いました。

それでは、AIネイティブの世代の子供たちを持つ子育て世代の皆さま、AI時代でも楽しく子育てしましょう！
長文お付き合いいただき、ありがとうございました。
