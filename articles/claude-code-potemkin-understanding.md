---
title: "Claude Code でポチョムキン理解と戦う"
emoji: "🎭"
type: "tech"
topics: ["claudecode", "llm", "ai", "プログラミング", "ポチョムキン理解"]
published: true
---

## この記事を読むべき人

- Claude CodeやGitHub Copilotなど、AIアシスタントを日常的に使っている開発者
- AIが生成したコードの品質に不安を感じている人
- LLM（大規模言語モデル）の限界を理解して、より効果的に活用したい人

## ポチョムキン理解とは何か - AIが抱える弱点

![AIは知っているのにできない](/images/claude-code-potemkin-understanding/ai-knows-but-cannot-do.jpeg)

「ポチョムキン理解（Potemkin Understanding）」とは、**LLM（大規模言語モデル）が概念を正しく説明できるにもかかわらず、その知識を実際の応用場面で一貫して使えない、いわば「見せかけの理解」** を指します。

この言葉は「ポチョムキン村」に由来します。18世紀のロシアで、エカチェリーナ2世の視察のために、実際には何もない場所に見せかけだけの村を作ったという逸話から、「表面だけ立派で中身がない」という意味で使われるようになりました。

### ハーバード大学などの研究で明らかになった事実

2025年6月26日、ハーバード大学、MIT、シカゴ大学の研究者らが共同で発表した論文で、この問題が明らかになりました。

**研究結果の概要**:

- **対象**: GPT-4o、Claude、Geminiなど主要な7つのLLM
- **定義の正答率**: 平均94.2%（概念の説明は完璧）
- **応用問題でのポチョムキン率**:
  - 分類タスク: 55%
  - 生成タスク: 40%
  - 編集タスク: 40%

つまり、**AIは概念を完璧に説明できるが、その概念を使った実際のタスクでは約40-55%が失敗する**という衝撃的な結果です。

### 具体例: RESTful API設計の矛盾

開発現場でよくある例を見てみましょう:

> **人間**: 「RESTful APIの設計原則に従ってエンドポイントを設計して」

> **AI**: 「RESTful APIでは、リソース指向の設計が重要です。HTTPメソッドはCRUD操作に対応させ、GETは取得、POSTは作成、PUTは更新、DELETEは削除に使います」

→ **完璧な説明!**

> **人間**: 「では、ユーザー管理のエンドポイントを実装して」

> **AI**: 「実装しました」

```typescript
// 生成されたコード
app.post('/deleteUser', async (req, res) => { // ← POSTでdelete?
  await User.delete(req.body.id)
})

app.get('/createUser', async (req, res) => { // ← GETでcreate?
  await User.create(req.query)
})
```

> **人間**: 「これRESTfulの原則に従ってないですよね? POSTで削除、GETで作成になってます」

> **AI**: 「仰る通りです！修正しますか？」

→ **さっきの説明なんだったんだ！最初からやってよ!**

説明はできるのに、実装できない。これがポチョムキン理解です。

## なぜポチョムキン理解が起こるのか - 宣言的知識と手続的知識の分離

この矛盾の原因は、**「説明する知識（宣言的知識）」と「それを使う知識（手続的知識）」が完全に分離している**ことにあります。

### 人間の学習プロセス

```
1. 概念を学ぶ（宣言的知識）
   ↓
2. 練習して実践する
   ↓
3. 概念と実践が結びつく（手続的知識）
   ↓
4. 応用できるようになる
```

### LLMの学習プロセス

```
1. 大量のテキストから概念の説明を学習（宣言的知識）
   ↓
2. 大量のコード例から実装パターンを学習（手続的知識）
   ↓
   しかし、この2つが内部で結びついていない!
   ↓
3. 宣言的知識は保持される
   ↓
結果:
✗ 一貫した実装はできない（手続的知識が不完全）
○ 間違いの指摘はできる（宣言的知識は機能）
```

モデルは概念を「知っている」と応答し、実装時には矛盾が顕在化します。しかし重要なのは、**指摘された間違いは理解できる**という点です。

### ハルシネーションとの違い

- **ハルシネーション**: 存在しない事実を作り出す（わかりやすい誤り）
- **ポチョムキン理解**: 正しい説明と矛盾した実装（検出が困難）

ポチョムキン理解は、表面的な正しさの裏に隠された微妙な論理的矛盾を解き明かす必要があり、**検出が困難**です。

## ポチョムキン理解の弱点を軽減する実践的な方法

![ポチョムキン理解の特性](/images/claude-code-potemkin-understanding/potemkin-understanding-concept.jpeg)

ポチョムキン理解は確かにLLMの弱点です。しかし、重要な特性があります。**実装はできなくても、間違いは指摘できる**という検証能力は持っているのです。

### ポチョムキン理解の重要な特性

> **AI**: 実装しました
```typescript
app.post('/deleteUser', async (req, res) => {
  await User.delete(req.body.id)
})
```

→ 実際にはPOSTで削除を実装してしまう

> **人間**: 「このエンドポイントがRESTfulの原則に従っているか検証して」

> **AI**: 「いいえ、これはRESTfulの原則に反しています。POSTは作成に使うべきで、削除には `DELETE /users/:id` を使うべきです」

→ **間違いの指摘はできる** ✓

**この検証能力を活用すれば、AIに自分自身の実装を検証させることで、弱点を補うことができます。**

## ポチョムキン理解の弱点を軽減する5つの方法


### 1. AIに実装を検証させる - 「実装」→「検証」のサイクル

**従来の使い方（危険）**:

> あなた: 「RESTful APIのエンドポイントを実装して」
> Claude Code: [コード生成]
> あなた: 「動いた!OK!」

→ 実装の正しさを検証していない

**改善した使い方（安全）**:

> あなた: 「RESTful APIのエンドポイントを実装して」
> Claude Code: [コード生成]
> あなた: 「このコードがRESTfulの原則に従っているか検証して。
>        問題があれば具体的に指摘して」
> Claude Code: 「以下の問題があります:
>            1. `POST /deleteUser` - DELETEメソッドを使うべき
>            2. `GET /createUser` - POSTメソッドを使うべき」

→ 間違いを指摘できる！

**ポイント**: 実装後、必ずAI自身に検証させる。宣言的知識（原則の理解）は機能するため、矛盾を発見できる。

### 2. 原則を明示して実装を要求する

**悪い使い方**:

> あなた: 「ユーザー入力を表示する機能を実装して」

→ XSS脆弱性のあるコードが生成される可能性

**良い使い方**:

> あなた: 「ユーザー入力を表示する機能を実装して。
>        XSS対策として、innerHTML は使わず textContent を使うこと。
>        実装後、なぜこの実装がXSS対策になるのか説明して」

**ポイント**: 原則を明示し、実装後に理由の説明を求めることで、一貫性を担保する。

### 3. AIに自分自身のコードを批判させる - 検証能力の活用

「間違いは指摘できる」という検証能力を最大限に活用します。

**効果的な検証方法**:

> あなた: 「このコードのパフォーマンス上の問題点を5つ挙げて」
> Claude Code: 「以下の問題があります:
>            1. 不要な再レンダリングが発生
>            2. メモ化されていない計算
>            3. ...」

→ 自分が書いたコードの問題を正確に指摘できる！

> あなた: 「では、これらの問題を修正したコードを書いて」
> Claude Code: [改善されたコードを生成]

**ポイント**: 一度問題を認識させれば、修正の精度が上がる

### 4. 複数案を提示させ、AIに評価させる

複数の実装案を生成させ、**AI自身に各案を評価させる**ことで、宣言的知識を活用します。

**従来の使い方**:

> あなた: 「キャッシュ機能を実装して」

> Claude Code: [1つの実装を生成]

> あなた: 「OK!」

→ その実装が最適かわからない

**改善した使い方**:

> あなた: 「キャッシュ機能の実装案を3つ提案して」

> Claude Code: [3つの実装案を提示]

> あなた: 「各案について、セキュリティ、パフォーマンス、保守性の観点から評価して。問題点も指摘して」

> Claude Code: 「案1: セキュリティに問題あり（理由...）
>            案2: パフォーマンスが劣る（理由...）
>            案3: 最もバランスが良い」

→ AIの宣言的知識で各案を評価できる！

**ポイント**: 実装だけでなく、評価もさせることで、矛盾のない案を選択できる。

### 5. テストケースでAIに自己検証させる

AIに実装とテストの両方を書かせることで、**宣言的知識（テスト）と手続的知識（実装）の矛盾を浮き彫り**にします。

**効果的な使い方**:

> あなた: 「RESTful APIを実装して。
>        さらに、RESTful の原則に従っているかを検証する
>        テストケースも作成して」

> Claude Code: [実装とテストを生成]

> あなた: [テストを実行]

→ テストが失敗！

> あなた: 「テストが失敗しました。なぜですか?」

> Claude Code: 「実装が間違っていました。`POST /deleteUser` はDELETEメソッドを使うべきです」

→ テストを通じて実装の間違いを指摘できる！

**ポイント**:
- テストは宣言的知識に基づいて書かれるため、正確
- テストと実装の矛盾から、ポチョムキン理解を検出できる
- AIに「なぜテストが失敗したのか」を説明させることで、修正の精度が上がる


### ポチョムキン理解の弱点を軽減する検証チェックリスト

生成されたコードを受け取ったら、**AI自身に検証させる**ことを検討してください:

- [ ] **実装の検証**: 「このコードが〇〇の原則に従っているか検証して」
- [ ] **問題点の列挙**: 「このコードの問題点を5つ挙げて」
- [ ] **改善案の提示**: 「これらの問題をどう修正すべきか説明して」
- [ ] **代替案の評価**: 「別の実装方法を2つ提案して、各案の問題点を指摘して」
- [ ] **テストの作成**: 「このコードが正しく動作することを検証するテストを書いて」
- [ ] **テスト失敗の分析**: テストが失敗したら「なぜ失敗したか説明して」
- [ ] **境界条件の検証**: 「エッジケースでこのコードに問題がないか検証して」

**重要**: 人間が検証するのではなく、**AI自身に検証させる**ことがポイントです。

## 実践: Claude Codeでの実践方法

### `plans.md`で実装前に設計を検証する

Claude Codeに限らずですが、実装前に`plans.md`に実装計画を書き出す手法が非常に有効です。

**実践例**:

> あなた: 「RESTful APIのエンドポイントを実装する前に、
>        plans.mdに実装計画を書いて」
> Claude Code: [plans.mdに設計原則と実装方針を記述]
>
``` plans.md:
 # RESTful API実装計画

 ## 設計原則
 - リソース指向の設計
 - HTTPメソッドとCRUD操作の対応
   - GET: リソースの取得
   - POST: リソースの作成
   - PUT: リソースの更新
   - DELETE: リソースの削除

 ## エンドポイント設計
 - GET /users - ユーザー一覧取得
 - POST /users - ユーザー作成
 - PUT /users/:id - ユーザー更新
 - DELETE /users/:id - ユーザー削除

 ## 検証ポイント
 - 各エンドポイントのHTTPメソッドとCRUD操作が対応しているか
 - リソース名が複数形で統一されているか
 - RESTful原則に従った設計であることを確認
```
> あなた: [plans.mdを確認して、設計の一貫性を検証]
>      「この設計でRESTfulの原則に従っているか説明して」

> Claude Code: [説明]

> あなた: [説明とplans.mdの設計が一致していることを確認]
>      「OKなら実装して」

**メリット**:
- 実装前に設計の矛盾を発見できる
- AIに「なぜこの設計なのか」を説明させることで、一貫性を担保できる
- 実装後にplans.mdと照らし合わせて検証できる
- ポチョムキン理解を事前に防ぐことができる

### Claude Skillで検証を効率化する

ポチョムキン理解の検出作業を、Claude Skillとして実装することで、効率化と一貫性を高めることができます。

#### 検出スキルの実装

検出作業を専用のスキルとして作成します:

```markdown
# .claude/skills/validate-impl.md

このスキルは、実装に矛盾がないか、原則に従っているかを検証します。

## 検証ルール

以下のルールに従って、コードを検証してください:

1. **説明と実装の一貫性**
   - コードの設計思想を説明させる
   - 説明と実装が一致しているか検証する

2. **原則との整合性**
   - @plans.md をみて計画で定めた原則に従っているか
   - 説明された原則が実装に反映されているか

3. **矛盾の検出**
   - コードの問題点を列挙させる
   - なぜ最初からその問題を避けなかったのか質問する

4. **代替案の検討**
   - 別の実装方法を複数提案させる
   - 各案の一貫性を比較する
```

#### ルールの一元化

実装スキルと検出スキルの両方から、同じルールファイルを参照することで、ツールの一貫性を保つことができます:


```markdown
# .claude/skills/api-implementation.md

コーディング規約は [coding-standards.md](../rules/coding-standards.md) を参照してください。

このルールに従ってAPIを実装してください。
```

```markdown
# .claude/skills/validate-impl.md

コーディング規約は [coding-standards.md](../rules/coding-standards.md) を参照してください。

このルールに従って実装されているか検証してください。
```



```markdown
# .claude/rules/coding-standards.md

## RESTful API設計原則
- リソース指向の設計
- HTTPメソッドとCRUD操作の対応
- ...

## セキュリティ原則
- XSS対策: innerHTML禁止、textContent使用
- CSRF対策: トークン検証
- ...
```
※ `.claude/rules/*` は claude 公式のディレクトリ構造ではなく、rulesを共通管理のための筆者の独自構成です


**メリット**:
- 実装と検証で同じ基準を使うため、矛盾が生じない
- ルールの更新が一箇所で済む
- チーム全体で一貫した開発基準を共有できる

### Subagentで客観的な検証を行う

Claude Codeのsubagentを使うことで、過去のコンテキストに引きずられずに、客観的な検証ができます。

> あなた: 「このコードをポチョムキン理解の観点から検証して」

> Claude Code: [適切なsubagentを自動選択して検証を開始]
> Subagent: [新しいコンテキストで検証開始]

**なぜsubagentが有効なのか**:

1. **コンテキストの分離**: メインの会話では「実装した本人」として説明を繰り返すため、矛盾に気づきにくい。subagentは新しいコンテキストで評価するため、矛盾を見つけやすい。

2. **客観性の確保**: 過去の会話で「OKを出した」という心理的なバイアスがないため、厳しく評価できる。

3. **複数の視点**: 異なるsubagentを使って複数回検証することで、様々な角度から問題を発見できる。

レビューや検証をsubagentに任せることで、既存のコンテキストに引きずられないポチョムキン理解の検出精度が向上します。

## まとめ: ポチョムキン理解という弱点を理解し、検証能力を活用する

### ポチョムキン理解とは

- **定義**: LLMが概念を説明できるが、実際の応用で一貫して使えない「見せかけの理解」
- **原因**: 宣言的知識と手続的知識の分離
- **重要な特性**: **実装はできなくても、間違いは指摘できる**
- **研究**: ハーバード大学など、応用問題でのポチョムキン率40-55%

### ポチョムキン理解の弱点を軽減する5つの方法

1. **AIに実装を検証させる** - 実装後、AI自身に問題点を指摘させる
2. **原則を明示して実装を要求** - 守るべき原則を事前に指定する
3. **AIに自分自身のコードを批判させる** - 宣言的知識で矛盾を発見させる
4. **複数案を提示させ、AIに評価させる** - AI自身に各案の問題点を指摘させる
5. **テストでAIに自己検証させる** - テストと実装の矛盾から問題を発見

### ポチョムキン理解という弱点と、宣言的知識という強み

**LLMは「間違いを指摘できる」という検証能力は持っている**ので、これを活用します。

**この検証能力を活用すれば**:

- AIの出力を盲目的に信じず、AI自身に検証させる
- **実装→検証→修正のサイクル**で品質を高める
- 宣言的知識（原則の理解）を活用して矛盾を発見する
- 初回の実装が完璧でなくても、自己検証で改善できる

この検証は、Claude Codeのスキルやコマンドを強力に活かせます。
その弱点を理解し検証能力という強みを Claude Code と合わせて活用することで、より安全で質の高い開発ができます。

## 参考リンク

- [ポチョムキン理解とは？ハーバード大等が暴いたLLMの決定的弱点](https://xenospectrum.com/what-is-potemkin-understanding-the-decisive-weakness-of-llm-exposed-by-harvard-university-and-others/)
- [ポチョムキン理解について (YouTube)](https://www.youtube.com/watch?v=CgR3EEQ1A_Q)
- [原論文: On the Potemkin Understanding of Large Language Models (arXiv)](https://arxiv.org/abs/2506.12345)
